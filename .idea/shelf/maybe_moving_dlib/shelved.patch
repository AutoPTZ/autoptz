Index: .idea/workspace.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project version=\"4\">\n  <component name=\"AutoImportSettings\">\n    <option name=\"autoReloadType\" value=\"SELECTIVE\" />\n  </component>\n  <component name=\"ChangeListManager\">\n    <list default=\"true\" id=\"38ebf632-8fcc-432a-b960-3dfb24f85e9e\" name=\"Changes\" comment=\"\">\n      <change beforePath=\"$PROJECT_DIR$/.idea/workspace.xml\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/.idea/workspace.xml\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/logic/facial_tracking/testing_image_processor.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/logic/facial_tracking/testing_image_processor.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/views/homepage/main_window.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/views/homepage/main_window.py\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/views/widgets/camera_widget.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/views/widgets/camera_widget.py\" afterDir=\"false\" />\n    </list>\n    <option name=\"SHOW_DIALOG\" value=\"false\" />\n    <option name=\"HIGHLIGHT_CONFLICTS\" value=\"true\" />\n    <option name=\"HIGHLIGHT_NON_ACTIVE_CHANGELIST\" value=\"false\" />\n    <option name=\"LAST_RESOLUTION\" value=\"IGNORE\" />\n  </component>\n  <component name=\"FileTemplateManagerImpl\">\n    <option name=\"RECENT_TEMPLATES\">\n      <list>\n        <option value=\"Python Script\" />\n      </list>\n    </option>\n  </component>\n  <component name=\"Git.Settings\">\n    <option name=\"RECENT_BRANCH_BY_REPOSITORY\">\n      <map>\n        <entry key=\"$PROJECT_DIR$\" value=\"main\" />\n      </map>\n    </option>\n    <option name=\"RECENT_GIT_ROOT_PATH\" value=\"$PROJECT_DIR$\" />\n  </component>\n  <component name=\"MarkdownSettingsMigration\">\n    <option name=\"stateVersion\" value=\"1\" />\n  </component>\n  <component name=\"ProblemsViewState\">\n    <option name=\"selectedTabId\" value=\"CurrentFile\" />\n  </component>\n  <component name=\"ProjectId\" id=\"2G5UlvkeEckFZ7APx1GRpTIhrk8\" />\n  <component name=\"ProjectLevelVcsManager\" settingsEditedManually=\"true\" />\n  <component name=\"ProjectViewState\">\n    <option name=\"hideEmptyMiddlePackages\" value=\"true\" />\n    <option name=\"showLibraryContents\" value=\"true\" />\n  </component>\n  <component name=\"PropertiesComponent\">{\n  &quot;keyToString&quot;: {\n    &quot;ASKED_ADD_EXTERNAL_FILES&quot;: &quot;true&quot;,\n    &quot;RunOnceActivity.OpenProjectViewOnStart&quot;: &quot;true&quot;,\n    &quot;RunOnceActivity.ShowReadmeOnStart&quot;: &quot;true&quot;,\n    &quot;last_opened_file_path&quot;: &quot;/Users/prince/development/autoptz/logic/facial_tracking/images&quot;,\n    &quot;settings.editor.selected.configurable&quot;: &quot;Errors&quot;\n  }\n}</component>\n  <component name=\"RecentsManager\">\n    <key name=\"CopyFile.RECENT_KEYS\">\n      <recent name=\"$PROJECT_DIR$/logic/facial_tracking/images\" />\n      <recent name=\"$PROJECT_DIR$\" />\n      <recent name=\"$PROJECT_DIR$/logic/facial_tracking\" />\n    </key>\n    <key name=\"MoveFile.RECENT_KEYS\">\n      <recent name=\"$PROJECT_DIR$/views/test\" />\n      <recent name=\"C:\\Users\\steve\\development\\autoptz\\views\\functions\" />\n      <recent name=\"$PROJECT_DIR$/libraries\" />\n      <recent name=\"$PROJECT_DIR$/shared\" />\n      <recent name=\"$PROJECT_DIR$/ui/widgets\" />\n    </key>\n  </component>\n  <component name=\"RunManager\" selected=\"Python.startup\">\n    <configuration name=\"flow_layout\" type=\"PythonConfigurationType\" factoryName=\"Python\" temporary=\"true\" nameIsGenerated=\"true\">\n      <module name=\"autoptz\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"$PROJECT_DIR$/views/homepage\" />\n      <option name=\"IS_MODULE_SDK\" value=\"true\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/views/homepage/flow_layout.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"startup\" type=\"PythonConfigurationType\" factoryName=\"Python\" temporary=\"true\" nameIsGenerated=\"true\">\n      <module name=\"autoptz\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"$PROJECT_DIR$\" />\n      <option name=\"IS_MODULE_SDK\" value=\"true\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/startup.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <recent_temporary>\n      <list>\n        <item itemvalue=\"Python.startup\" />\n        <item itemvalue=\"Python.flow_layout\" />\n      </list>\n    </recent_temporary>\n  </component>\n  <component name=\"SpellCheckerSettings\" RuntimeDictionaries=\"0\" Folders=\"0\" CustomDictionaries=\"0\" DefaultDictionary=\"application-level\" UseSingleDictionary=\"true\" transferred=\"true\" />\n  <component name=\"TaskManager\">\n    <task active=\"true\" id=\"Default\" summary=\"Default task\">\n      <changelist id=\"38ebf632-8fcc-432a-b960-3dfb24f85e9e\" name=\"Changes\" comment=\"\" />\n      <created>1665678093482</created>\n      <option name=\"number\" value=\"Default\" />\n      <option name=\"presentableId\" value=\"Default\" />\n      <updated>1665678093482</updated>\n    </task>\n    <servers />\n  </component>\n  <component name=\"Vcs.Log.Tabs.Properties\">\n    <option name=\"TAB_STATES\">\n      <map>\n        <entry key=\"MAIN\">\n          <value>\n            <State />\n          </value>\n        </entry>\n      </map>\n    </option>\n  </component>\n  <component name=\"XDebuggerManager\">\n    <breakpoint-manager>\n      <default-breakpoints>\n        <breakpoint type=\"python-exception\">\n          <properties notifyOnTerminate=\"true\" exception=\"BaseException\">\n            <option name=\"notifyOnTerminate\" value=\"true\" />\n          </properties>\n        </breakpoint>\n      </default-breakpoints>\n    </breakpoint-manager>\n  </component>\n</project>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/workspace.xml b/.idea/workspace.xml
--- a/.idea/workspace.xml	(revision ddfcc307b70213f1b1cd12fe34f293537998ffeb)
+++ b/.idea/workspace.xml	(date 1669143465719)
@@ -5,6 +5,7 @@
   </component>
   <component name="ChangeListManager">
     <list default="true" id="38ebf632-8fcc-432a-b960-3dfb24f85e9e" name="Changes" comment="">
+      <change afterPath="$PROJECT_DIR$/logic/facial_tracking/testing_person_tracking.py" afterDir="false" />
       <change beforePath="$PROJECT_DIR$/.idea/workspace.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/workspace.xml" afterDir="false" />
       <change beforePath="$PROJECT_DIR$/logic/facial_tracking/testing_image_processor.py" beforeDir="false" afterPath="$PROJECT_DIR$/logic/facial_tracking/testing_image_processor.py" afterDir="false" />
       <change beforePath="$PROJECT_DIR$/views/homepage/main_window.py" beforeDir="false" afterPath="$PROJECT_DIR$/views/homepage/main_window.py" afterDir="false" />
Index: logic/facial_tracking/testing_image_processor.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import multiprocessing\nfrom multiprocessing import Process, Pool\n\nimport cv2\nfrom PySide6.QtCore import QThread\n\nimport shared.constants as constants\nfrom threading import Thread\nimport os\nimport pickle\nimport math\nimport numpy as np\nimport time\nimport imutils\nimport timeit\nimport dlib\n\nfrom libraries.face_recognition import FaceRec\nfrom logic.facial_tracking.dialogs.train_face import TrainerDlg\nfrom multiprocessing import Process\n\n\ndef face_confidence(face_distance, face_match_threshold=0.6):\n    \"\"\"\n    Confidence calculation for Facial Recognition\n    :param face_distance:\n    :param face_match_threshold:\n    :return:\n    \"\"\"\n    threshold = (1.0 - face_match_threshold)\n    linear_val = (1.0 - face_distance) / (threshold * 2.0)\n\n    if face_distance > face_match_threshold:\n        return str(round(linear_val * 100, 2)) + '%'\n    else:\n        value = (linear_val + ((1.0 - linear_val) * math.pow((linear_val - 0.5) * 2, 0.2))) * 100\n        return str(round(value, 2)) + '%'\n\n\n# def recognize_face(frame):\n#     tic = timeit.default_timer()\n#     encoding_data = pickle.loads(open(constants.ENCODINGS_PATH, \"rb\").read())\n#     face_rec = FaceRec()\n#     face_locations = []\n#     face_names = []\n#     confidence_list = []\n#     if frame is not None:\n#         # Resize frame of video to 1/2 size for faster face recognition processing\n#         small_frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\n#\n#         # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n#         rgb_small_frame = small_frame[:, :, ::-1]\n#\n#         # Find all the faces and face encodings in the current frame of video\n#         face_locations = face_rec.face_locations(rgb_small_frame, number_of_times_to_upsample=0, model=\"cnn\")\n#         face_encodings = face_rec.face_encodings(rgb_small_frame, face_locations)\n#         for face_encoding in face_encodings:\n#             # See if the face is a match for the known face(s)\n#             matches = face_rec.compare_faces(encoding_data['encodings'], face_encoding)\n#             name = \"Unknown\"\n#             confidence = ''\n#             # Or instead, use the known face with the smallest distance to the new face\n#             face_distances = face_rec.face_distance(encoding_data['encodings'], face_encoding)\n#             best_match_index = np.argmin(face_distances)\n#             if matches[best_match_index]:\n#                 name = encoding_data['names'][best_match_index]\n#                 confidence = face_confidence(face_distances[best_match_index])\n#             face_names.append(name)\n#             confidence_list.append(confidence)\n#     toc = timeit.default_timer()\n#     print(f'Done in {toc - tic}')\n#     print(face_locations, face_names, confidence_list)\n#     return face_locations, face_names, confidence_list\n\n\nclass ImageProcessor(Thread):\n    \"\"\"\n    Threaded ImageProcessor for CameraWidget.\n    Used for added faces to database and facial recognition for now.\n    *** NEED TO ADD FACIAL TRACKING ***\n    \"\"\"\n    def __init__(self, stream_thread):\n        super().__init__()\n        self.stream = stream_thread\n        self._run_flag = True\n\n        # CameraWidget will access these four variables for Facial Recognition (3) and Tracking (1)\n        self.face_locations = None\n        self.face_names = None\n        self.confidence_list = None\n        self.tracked_location = None\n\n        # Variables for Adding Faces, Recognition, and Tracking\n        self.count = 0\n        self.add_name = None\n        self.face_rec = FaceRec()\n        self.encoding_data = None\n        self.check_encodings()\n\n    def run(self):\n        \"\"\"\n        Runs continuously on CameraWidget.start() to provide the latest face boxes for CameraWidget to drawn until _run_flag is False.\n        \"\"\"\n        while self._run_flag:\n            frame = self.stream.cv_img\n            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n            if self.add_name:\n                self.add_face(frame=frame, gray_frame=gray_frame)\n            elif self.encoding_data is not None:\n                try:\n                    self.recognize_face(frame)\n                except Exception as e:\n                    print(e)\n                # p = Pool(processes=6)\n                # data = p.map(recognize_face, [frame])\n                #\n                # for loc, name, conf in data:\n                #     self.face_locations = loc\n                #     self.face_names = name\n                #     self.confidence_list = conf\n\n                # recognition = Process(target=recognize_face, args=(frame,))\n                # recognition.start()\n                # recognition.join()\n            else:  # Free up threads and fixes Window's performance issue with useless thread\n                self.stop()\n\n    def add_face(self, frame, gray_frame):\n        \"\"\"\n        If there is a face to add, then use OpenCV Cascades to save images to database and send for training.\n        :param frame: Is used for saving the complete original image.\n        :param gray_frame: Is used for OpenCV face detection.\n        \"\"\"\n        min_w = 0.1 * gray_frame.shape[1]\n        min_h = 0.1 * gray_frame.shape[0]\n\n        faces = constants.FACE_CASCADE.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=10,\n                                                        minSize=(int(min_w), int(min_h)))\n        time.sleep(0.07)  # add artificial timer sleep so users can see the boxes draw\n        self.face_locations = []\n        self.face_names = []\n        self.confidence_list = []\n        for x, y, w, h in faces:\n            self.count += 1\n            location = constants.IMAGE_PATH + self.add_name + '/' + str(self.count) + '.jpg'\n            print(\"\\n [INFO] Creating Images at \" + location)\n            cv2.imwrite(location, frame)\n            self.face_names.append(\"Adding: \" + self.add_name)\n            self.face_locations = [(int(y / 2), int((x + w) / 2), int((y + h) / 2), int(x / 2))]\n            self.confidence_list.append(\"100%\")\n\n        if self.count >= 10:  # Take 50 face sample and stop video\n            self.add_name = None\n            self.count = 0\n            self.face_locations = None\n            self.face_names = None\n            # send signal for TrainingDlg\n\n    def recognize_face(self, frame):\n        \"\"\"\n        Runs grabbed frame through Facial Recognition Library and sets Face Locations, Names, and Confidences in a list.\n        :param frame:\n        \"\"\"\n        if frame is not None:\n            # Resize frame of video to 1/2 size for faster face recognition processing\n            small_frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\n\n            # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n            rgb_small_frame = small_frame[:, :, ::-1]\n\n            # Find all the faces and face encodings in the current frame of video\n            self.face_locations = self.face_rec.face_locations(rgb_small_frame, number_of_times_to_upsample=0)\n            face_encodings = self.face_rec.face_encodings(rgb_small_frame, self.face_locations)\n\n            self.face_names = []\n            self.confidence_list = []\n\n            for face_encoding in face_encodings:\n                # See if the face is a match for the known face(s)\n                matches = self.face_rec.compare_faces(self.encoding_data['encodings'], face_encoding)\n                name = \"Unknown\"\n                confidence = ''\n                # Or instead, use the known face with the smallest distance to the new face\n                face_distances = self.face_rec.face_distance(self.encoding_data['encodings'], face_encoding)\n                best_match_index = np.argmin(face_distances)\n                if matches[best_match_index]:\n                    name = self.encoding_data['names'][best_match_index]\n                    confidence = face_confidence(face_distances[best_match_index], 0.6)\n                self.face_names.append(name)\n                self.confidence_list.append(confidence)\n\n\n    def check_encodings(self):\n        \"\"\"\n        Refresh encodings_data to use the latest trainer data. If there is any.\n        \"\"\"\n        self.encoding_data = None\n        if os.path.exists(constants.ENCODINGS_PATH):\n            self.encoding_data = pickle.loads(open(constants.ENCODINGS_PATH, \"rb\").read())\n\n    def stop(self):\n        \"\"\"Sets run flag to False and waits for thread to finish\"\"\"\n        self._run_flag = False\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/logic/facial_tracking/testing_image_processor.py b/logic/facial_tracking/testing_image_processor.py
--- a/logic/facial_tracking/testing_image_processor.py	(revision ddfcc307b70213f1b1cd12fe34f293537998ffeb)
+++ b/logic/facial_tracking/testing_image_processor.py	(date 1669144292761)
@@ -37,48 +37,49 @@
         return str(round(value, 2)) + '%'
 
 
-# def recognize_face(frame):
-#     tic = timeit.default_timer()
-#     encoding_data = pickle.loads(open(constants.ENCODINGS_PATH, "rb").read())
-#     face_rec = FaceRec()
-#     face_locations = []
-#     face_names = []
-#     confidence_list = []
-#     if frame is not None:
-#         # Resize frame of video to 1/2 size for faster face recognition processing
-#         small_frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)
-#
-#         # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)
-#         rgb_small_frame = small_frame[:, :, ::-1]
-#
-#         # Find all the faces and face encodings in the current frame of video
-#         face_locations = face_rec.face_locations(rgb_small_frame, number_of_times_to_upsample=0, model="cnn")
-#         face_encodings = face_rec.face_encodings(rgb_small_frame, face_locations)
-#         for face_encoding in face_encodings:
-#             # See if the face is a match for the known face(s)
-#             matches = face_rec.compare_faces(encoding_data['encodings'], face_encoding)
-#             name = "Unknown"
-#             confidence = ''
-#             # Or instead, use the known face with the smallest distance to the new face
-#             face_distances = face_rec.face_distance(encoding_data['encodings'], face_encoding)
-#             best_match_index = np.argmin(face_distances)
-#             if matches[best_match_index]:
-#                 name = encoding_data['names'][best_match_index]
-#                 confidence = face_confidence(face_distances[best_match_index])
-#             face_names.append(name)
-#             confidence_list.append(confidence)
-#     toc = timeit.default_timer()
-#     print(f'Done in {toc - tic}')
-#     print(face_locations, face_names, confidence_list)
-#     return face_locations, face_names, confidence_list
+def recognize_face(frame):
+    tic = timeit.default_timer()
+    encoding_data = pickle.loads(open(constants.ENCODINGS_PATH, "rb").read())
+    face_rec = FaceRec()
+    face_locations = []
+    face_names = []
+    confidence_list = []
+    if frame is not None:
+        # Resize frame of video to 1/2 size for faster face recognition processing
+        small_frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)
+
+        # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)
+        rgb_small_frame = small_frame[:, :, ::-1]
+
+        # Find all the faces and face encodings in the current frame of video
+        face_locations = face_rec.face_locations(rgb_small_frame, number_of_times_to_upsample=0, model="cnn")
+        face_encodings = face_rec.face_encodings(rgb_small_frame, face_locations)
+        for face_encoding in face_encodings:
+            # See if the face is a match for the known face(s)
+            matches = face_rec.compare_faces(encoding_data['encodings'], face_encoding)
+            name = "Unknown"
+            confidence = ''
+            # Or instead, use the known face with the smallest distance to the new face
+            face_distances = face_rec.face_distance(encoding_data['encodings'], face_encoding)
+            best_match_index = np.argmin(face_distances)
+            if matches[best_match_index]:
+                name = encoding_data['names'][best_match_index]
+                confidence = face_confidence(face_distances[best_match_index])
+            face_names.append(name)
+            confidence_list.append(confidence)
+    toc = timeit.default_timer()
+    print(f'Done in {toc - tic}')
+    # print(face_locations, face_names, confidence_list)
+    return face_locations, face_names, confidence_list
 
 
-class ImageProcessor(Thread):
+class ImageProcessor(QThread):
     """
     Threaded ImageProcessor for CameraWidget.
     Used for added faces to database and facial recognition for now.
     *** NEED TO ADD FACIAL TRACKING ***
     """
+
     def __init__(self, stream_thread):
         super().__init__()
         self.stream = stream_thread
@@ -96,6 +97,7 @@
         self.face_rec = FaceRec()
         self.encoding_data = None
         self.check_encodings()
+        # self.p = Pool(processes=100)
 
     def run(self):
         """
@@ -111,8 +113,7 @@
                     self.recognize_face(frame)
                 except Exception as e:
                     print(e)
-                # p = Pool(processes=6)
-                # data = p.map(recognize_face, [frame])
+                # data = self.p.map(recognize_face, [frame])
                 #
                 # for loc, name, conf in data:
                 #     self.face_locations = loc
@@ -189,7 +190,6 @@
                 self.face_names.append(name)
                 self.confidence_list.append(confidence)
 
-
     def check_encodings(self):
         """
         Refresh encodings_data to use the latest trainer data. If there is any.
@@ -201,3 +201,5 @@
     def stop(self):
         """Sets run flag to False and waits for thread to finish"""
         self._run_flag = False
+        self.wait()
+        self.deleteLater()
Index: views/homepage/main_window.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import os\nfrom functools import partial\nfrom PySide6 import QtCore, QtWidgets\nfrom PySide6.QtMultimedia import QMediaDevices\nfrom PySide6.QtWidgets import QMainWindow\n\nimport watchdog.events\nimport watchdog.observers\nimport shared.constants as constants\nfrom logic.camera_search.search_ndi import get_ndi_sources\nfrom logic.facial_tracking.move_visca_ptz import ViscaPTZ\nfrom logic.camera_search.get_serial_cameras import COMPorts\nfrom views.functions.show_dialogs_ui import ShowDialog\nfrom views.functions.assign_network_ptz_ui import AssignNetworkPTZDlg\nfrom views.functions.assign_visca_ptz_ui import AssignViscaPTZDlg\nfrom views.homepage.flow_layout import FlowLayout\nfrom shared.watch_trainer_directory import WatchTrainer\nfrom views.widgets.camera_widget import CameraWidget\n\n\nclass AutoPTZ_MainWindow(QMainWindow):\n    \"\"\"\n    Configures and Handles the AutoPTZ MainWindow UI\n    \"\"\"\n    def __init__(self, *args, **kwargs):\n\n        # setting up the UI and QT Threading\n        super(AutoPTZ_MainWindow, self).__init__(*args, **kwargs)\n        self.threadpool = QtCore.QThreadPool()\n        self.threadpool.maxThreadCount()\n\n        # setting up main window\n        self.setObjectName(\"AutoPTZ\")\n        self.resize(200, 450)\n        self.setAutoFillBackground(False)\n        self.setTabShape(QtWidgets.QTabWidget.TabShape.Rounded)\n        self.setDockNestingEnabled(False)\n\n        # base window widget\n        self.central_widget = QtWidgets.QWidget(self)\n        size_policy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Policy.Maximum,\n                                            QtWidgets.QSizePolicy.Policy.Preferred)\n        size_policy.setHorizontalStretch(0)\n        size_policy.setVerticalStretch(0)\n        size_policy.setHeightForWidth(self.central_widget.sizePolicy().hasHeightForWidth())\n        self.central_widget.setSizePolicy(size_policy)\n        self.central_widget.setObjectName(\"central_widget\")\n        self.gridLayout = QtWidgets.QGridLayout(self.central_widget)\n        self.gridLayout.setObjectName(\"gridLayout\")\n        self.setCentralWidget(self.central_widget)\n\n        # left tab menus\n        self.formTabWidget = QtWidgets.QTabWidget(self.central_widget)\n        size_policy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Policy.Maximum,\n                                            QtWidgets.QSizePolicy.Policy.Preferred)\n        size_policy.setHeightForWidth(self.formTabWidget.sizePolicy().hasHeightForWidth())\n        self.formTabWidget.setSizePolicy(size_policy)\n        self.formTabWidget.setObjectName(\"formTabWidget\")\n\n        # auto tab menu\n        self.selectedCamPage = QtWidgets.QWidget(self)\n        size_policy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Policy.Maximum,\n                                            QtWidgets.QSizePolicy.Policy.Preferred)\n        size_policy.setHeightForWidth(self.selectedCamPage.sizePolicy().hasHeightForWidth())\n        self.selectedCamPage.setSizePolicy(size_policy)\n        self.selectedCamPage.setMinimumSize(QtCore.QSize(163, 0))\n        self.selectedCamPage.setMaximumSize(QtCore.QSize(16777215, 428))\n        self.selectedCamPage.setObjectName(\"selectedCamPage\")\n        self.formLayout = QtWidgets.QFormLayout(self.selectedCamPage)\n        self.formLayout.setLabelAlignment(\n            QtCore.Qt.AlignmentFlag.AlignLeading | QtCore.Qt.AlignmentFlag.AlignLeft | QtCore.Qt.AlignmentFlag.AlignTop)\n        self.formLayout.setFormAlignment(\n            QtCore.Qt.AlignmentFlag.AlignLeading | QtCore.Qt.AlignmentFlag.AlignLeft | QtCore.Qt.AlignmentFlag.AlignTop)\n        self.formLayout.setObjectName(\"formLayout\")\n        self.select_face_dropdown = QtWidgets.QComboBox(self.selectedCamPage)\n        size_policy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Policy.MinimumExpanding,\n                                            QtWidgets.QSizePolicy.Policy.Fixed)\n        size_policy.setHeightForWidth(self.select_face_dropdown.sizePolicy().hasHeightForWidth())\n        self.select_face_dropdown.setSizePolicy(size_policy)\n        self.select_face_dropdown.setObjectName(\"select_face_dropdown\")\n        self.select_face_dropdown.setEnabled(False)\n        self.select_face_dropdown.currentTextChanged.connect(self.selected_face_change)\n        self.select_face_dropdown.addItem('')\n        if os.path.isdir(constants.IMAGE_PATH):\n            for folder in os.listdir(constants.IMAGE_PATH):\n                self.select_face_dropdown.addItem(folder)\n\n        # assign VISCA PTZ to Serial Camera Source\n        self.assign_network_ptz_btn = QtWidgets.QPushButton(self.selectedCamPage)\n        self.assign_network_ptz_btn.setGeometry(QtCore.QRect(10, 380, 150, 32))\n        self.assign_network_ptz_btn.setObjectName(\"assign_network_ptz_btn\")\n        self.assign_network_ptz_btn.hide()\n        self.unassign_network_ptz_btn = QtWidgets.QPushButton(self.selectedCamPage)\n        self.unassign_network_ptz_btn.setGeometry(QtCore.QRect(0, 380, 162, 32))\n        self.unassign_network_ptz_btn.setObjectName(\"unassign_visca_ptz_btn\")\n        self.unassign_network_ptz_btn.hide()\n        self.assign_network_ptz_btn.clicked.connect(self.assign_network_ptz_dlg)\n        self.unassign_network_ptz_btn.clicked.connect(self.unassign_network_ptz)\n\n        self.formLayout.setWidget(2, QtWidgets.QFormLayout.ItemRole.SpanningRole, self.select_face_dropdown)\n        self.enable_track = QtWidgets.QCheckBox(self.selectedCamPage)\n        size_policy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Policy.MinimumExpanding,\n                                            QtWidgets.QSizePolicy.Policy.Fixed)\n        size_policy.setHeightForWidth(self.enable_track.sizePolicy().hasHeightForWidth())\n        self.enable_track.setSizePolicy(size_policy)\n        self.enable_track.setChecked(False)\n        self.enable_track.setEnabled(False)\n        self.enable_track.setAutoRepeat(False)\n        self.enable_track.setAutoExclusive(False)\n        self.enable_track.stateChanged.connect(self.enable_track_change)\n        self.enable_track.setObjectName(\"enable_track\")\n        self.formLayout.setWidget(3, QtWidgets.QFormLayout.ItemRole.LabelRole, self.enable_track)\n        self.select_face_label = QtWidgets.QLabel(self.selectedCamPage)\n        size_policy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Policy.Maximum,\n                                            QtWidgets.QSizePolicy.Policy.Preferred)\n        size_policy.setHeightForWidth(self.select_face_label.sizePolicy().hasHeightForWidth())\n        self.select_face_label.setSizePolicy(size_policy)\n        self.select_face_label.setObjectName(\"select_face_label\")\n        self.formLayout.setWidget(1, QtWidgets.QFormLayout.ItemRole.LabelRole, self.select_face_label)\n        self.formTabWidget.addTab(self.selectedCamPage, \"\")\n\n        # manual control tab menu\n        self.manualControlPage = QtWidgets.QWidget()\n        size_policy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Policy.Maximum,\n                                            QtWidgets.QSizePolicy.Policy.MinimumExpanding)\n        size_policy.setHeightForWidth(self.manualControlPage.sizePolicy().hasHeightForWidth())\n        self.manualControlPage.setSizePolicy(size_policy)\n        self.manualControlPage.setMinimumSize(QtCore.QSize(163, 0))\n        self.manualControlPage.setMaximumSize(QtCore.QSize(16777215, 428))\n        self.manualControlPage.setObjectName(\"manualControlPage\")\n        self.select_camera_label = QtWidgets.QLabel(self.manualControlPage)\n        self.select_camera_label.setGeometry(QtCore.QRect(10, 30, 101, 21))\n        size_policy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Policy.Maximum,\n                                            QtWidgets.QSizePolicy.Policy.Preferred)\n        size_policy.setHeightForWidth(self.select_camera_label.sizePolicy().hasHeightForWidth())\n        self.select_camera_label.setSizePolicy(size_policy)\n        self.select_camera_label.setObjectName(\"select_camera_label\")\n        self.select_camera_dropdown = QtWidgets.QComboBox(self.manualControlPage)\n        self.select_camera_dropdown.setGeometry(QtCore.QRect(9, 51, 151, 26))\n        size_policy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Policy.MinimumExpanding,\n                                            QtWidgets.QSizePolicy.Policy.Fixed)\n        size_policy.setHeightForWidth(self.select_camera_dropdown.sizePolicy().hasHeightForWidth())\n        self.select_camera_dropdown.setSizePolicy(size_policy)\n        self.select_camera_dropdown.setObjectName(\"select_camera_dropdown\")\n        self.select_camera_dropdown.addItem(\"\")\n\n        # add all the USB VISCA devices to the dropdown menu\n        data_list = COMPorts.get_com_ports().data\n        for port in data_list:\n            if \"USB\" in port.description:\n                print(port.device, port.description, data_list.index(port))\n                self.select_camera_dropdown.addItem(port.device)\n\n        self.select_camera_dropdown.currentTextChanged.connect(self.init_manual_control)\n\n        # manual control buttons\n        self.gridLayoutWidget = QtWidgets.QWidget(self.manualControlPage)\n        self.gridLayoutWidget.setGeometry(QtCore.QRect(0, 100, 162, 131))\n        self.gridLayoutWidget.setObjectName(\"gridLayoutWidget\")\n        self.controller_layout = QtWidgets.QGridLayout(self.gridLayoutWidget)\n        # self.controller_layout.setSizeConstraint(QtWidgets.QLayout.SetNoConstraint)\n        self.controller_layout.setContentsMargins(0, 0, 0, 0)\n        self.controller_layout.setObjectName(\"controllerLayout\")\n        self.down_right_btn = QtWidgets.QPushButton(self.gridLayoutWidget)\n        size_policy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Policy.Preferred,\n                                            QtWidgets.QSizePolicy.Policy.Maximum)\n        size_policy.setHeightForWidth(self.down_right_btn.sizePolicy().hasHeightForWidth())\n        self.down_right_btn.setSizePolicy(size_policy)\n        self.down_right_btn.setIconSize(QtCore.QSize(10, 10))\n        self.down_right_btn.setFlat(False)\n        self.down_right_btn.setObjectName(\"down_right_btn\")\n        self.controller_layout.addWidget(self.down_right_btn, 2, 2, 1, 1)\n        self.up_btn = QtWidgets.QPushButton(self.gridLayoutWidget)\n        size_policy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Policy.Preferred,\n                                            QtWidgets.QSizePolicy.Policy.Maximum)\n        size_policy.setHeightForWidth(self.up_btn.sizePolicy().hasHeightForWidth())\n        self.up_btn.setSizePolicy(size_policy)\n        self.up_btn.setIconSize(QtCore.QSize(10, 10))\n        self.up_btn.setObjectName(\"up_btn\")\n        self.controller_layout.addWidget(self.up_btn, 0, 1, 1, 1)\n        self.up_left_btn = QtWidgets.QPushButton(self.gridLayoutWidget)\n        size_policy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Policy.Preferred,\n                                            QtWidgets.QSizePolicy.Policy.Maximum)\n        size_policy.setHeightForWidth(self.up_left_btn.sizePolicy().hasHeightForWidth())\n        self.up_left_btn.setSizePolicy(size_policy)\n        self.up_left_btn.setIconSize(QtCore.QSize(10, 10))\n        self.up_left_btn.setObjectName(\"up_left_btn\")\n        self.controller_layout.addWidget(self.up_left_btn, 0, 0, 1, 1)\n        self.left_btn = QtWidgets.QPushButton(self.gridLayoutWidget)\n        size_policy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Policy.Preferred,\n                                            QtWidgets.QSizePolicy.Policy.Maximum)\n        size_policy.setHeightForWidth(self.left_btn.sizePolicy().hasHeightForWidth())\n        self.left_btn.setSizePolicy(size_policy)\n        self.left_btn.setIconSize(QtCore.QSize(10, 10))\n        self.left_btn.setObjectName(\"left_btn\")\n        self.controller_layout.addWidget(self.left_btn, 1, 0, 1, 1)\n        self.down_left_btn = QtWidgets.QPushButton(self.gridLayoutWidget)\n        size_policy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Policy.Preferred,\n                                            QtWidgets.QSizePolicy.Policy.Maximum)\n        size_policy.setHeightForWidth(self.down_left_btn.sizePolicy().hasHeightForWidth())\n        self.down_left_btn.setSizePolicy(size_policy)\n        self.down_left_btn.setIconSize(QtCore.QSize(10, 10))\n        self.down_left_btn.setObjectName(\"down_left_btn\")\n        self.controller_layout.addWidget(self.down_left_btn, 2, 0, 1, 1)\n        self.up_right_btn = QtWidgets.QPushButton(self.gridLayoutWidget)\n        size_policy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Policy.Preferred,\n                                            QtWidgets.QSizePolicy.Policy.Maximum)\n        size_policy.setHeightForWidth(self.up_right_btn.sizePolicy().hasHeightForWidth())\n        self.up_right_btn.setSizePolicy(size_policy)\n        self.up_right_btn.setIconSize(QtCore.QSize(10, 10))\n        self.up_right_btn.setObjectName(\"up_right_btn\")\n        self.controller_layout.addWidget(self.up_right_btn, 0, 2, 1, 1)\n        self.right_btn = QtWidgets.QPushButton(self.gridLayoutWidget)\n        size_policy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Policy.Preferred,\n                                            QtWidgets.QSizePolicy.Policy.Maximum)\n        size_policy.setHeightForWidth(self.right_btn.sizePolicy().hasHeightForWidth())\n        self.right_btn.setSizePolicy(size_policy)\n        self.right_btn.setIconSize(QtCore.QSize(10, 10))\n        self.right_btn.setObjectName(\"right_btn\")\n        self.controller_layout.addWidget(self.right_btn, 1, 2, 1, 1)\n        self.down_btn = QtWidgets.QPushButton(self.gridLayoutWidget)\n        size_policy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Policy.Preferred,\n                                            QtWidgets.QSizePolicy.Policy.Maximum)\n        size_policy.setHeightForWidth(self.down_btn.sizePolicy().hasHeightForWidth())\n        self.down_btn.setSizePolicy(size_policy)\n        self.down_btn.setIconSize(QtCore.QSize(10, 10))\n        self.down_btn.setObjectName(\"down_btn\")\n        self.controller_layout.addWidget(self.down_btn, 2, 1, 1, 1)\n        self.home_btn = QtWidgets.QPushButton(self.gridLayoutWidget)\n        size_policy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Policy.Preferred,\n                                            QtWidgets.QSizePolicy.Policy.Maximum)\n        size_policy.setHeightForWidth(self.home_btn.sizePolicy().hasHeightForWidth())\n        self.home_btn.setSizePolicy(size_policy)\n        self.home_btn.setIconSize(QtCore.QSize(10, 10))\n        self.home_btn.setObjectName(\"home_btn\")\n        self.controller_layout.addWidget(self.home_btn, 1, 1, 1, 1)\n        self.horizontalLayoutWidget = QtWidgets.QWidget(self.manualControlPage)\n        self.horizontalLayoutWidget.setGeometry(QtCore.QRect(0, 240, 161, 32))\n        self.horizontalLayoutWidget.setObjectName(\"horizontalLayoutWidget\")\n        self.zoom_layout = QtWidgets.QHBoxLayout(self.horizontalLayoutWidget)\n        self.zoom_layout.setContentsMargins(0, 0, 0, 0)\n        self.zoom_layout.setObjectName(\"zoom_layout\")\n        self.zoom_in_btn = QtWidgets.QPushButton(self.horizontalLayoutWidget)\n        size_policy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Policy.Preferred,\n                                            QtWidgets.QSizePolicy.Policy.Preferred)\n        size_policy.setHeightForWidth(self.zoom_in_btn.sizePolicy().hasHeightForWidth())\n        self.zoom_in_btn.setSizePolicy(size_policy)\n        self.zoom_in_btn.setObjectName(\"zoom_in_btn\")\n        self.zoom_layout.addWidget(self.zoom_in_btn)\n        self.zoom_out_btn = QtWidgets.QPushButton(self.horizontalLayoutWidget)\n        size_policy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Policy.Preferred,\n                                            QtWidgets.QSizePolicy.Policy.Preferred)\n        size_policy.setHeightForWidth(self.zoom_out_btn.sizePolicy().hasHeightForWidth())\n        self.zoom_out_btn.setSizePolicy(size_policy)\n        self.zoom_out_btn.setObjectName(\"zoom_out_btn\")\n        self.zoom_layout.addWidget(self.zoom_out_btn)\n        self.horizontalLayoutWidget_2 = QtWidgets.QWidget(self.manualControlPage)\n        self.horizontalLayoutWidget_2.setGeometry(QtCore.QRect(0, 280, 161, 32))\n        self.horizontalLayoutWidget_2.setObjectName(\"horizontalLayoutWidget_2\")\n        self.focus_layout = QtWidgets.QHBoxLayout(self.horizontalLayoutWidget_2)\n        self.focus_layout.setContentsMargins(0, 0, 0, 0)\n        self.focus_layout.setObjectName(\"focus_layout\")\n        self.focus_plus_btn = QtWidgets.QPushButton(self.horizontalLayoutWidget_2)\n        size_policy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Policy.Preferred,\n                                            QtWidgets.QSizePolicy.Policy.Preferred)\n        size_policy.setHorizontalStretch(0)\n        size_policy.setVerticalStretch(0)\n        size_policy.setHeightForWidth(self.focus_plus_btn.sizePolicy().hasHeightForWidth())\n        self.focus_plus_btn.setSizePolicy(size_policy)\n        self.focus_plus_btn.setObjectName(\"focus_plus_btn\")\n        self.focus_layout.addWidget(self.focus_plus_btn)\n        self.focus_minus_btn = QtWidgets.QPushButton(self.horizontalLayoutWidget_2)\n        size_policy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Policy.Preferred,\n                                            QtWidgets.QSizePolicy.Policy.Preferred)\n        size_policy.setHorizontalStretch(0)\n        size_policy.setVerticalStretch(0)\n        size_policy.setHeightForWidth(self.focus_minus_btn.sizePolicy().hasHeightForWidth())\n        self.focus_minus_btn.setSizePolicy(size_policy)\n        self.focus_minus_btn.setObjectName(\"focus_minus_btn\")\n        self.focus_layout.addWidget(self.focus_minus_btn)\n        self.horizontalLayoutWidget_3 = QtWidgets.QWidget(self.manualControlPage)\n        self.horizontalLayoutWidget_3.setGeometry(QtCore.QRect(0, 320, 161, 32))\n        self.horizontalLayoutWidget_3.setObjectName(\"horizontalLayoutWidget_3\")\n        self.menu_layout = QtWidgets.QHBoxLayout(self.horizontalLayoutWidget_3)\n        self.menu_layout.setContentsMargins(0, 0, 0, 0)\n        self.menu_layout.setObjectName(\"menu_layout\")\n        self.menu_btn = QtWidgets.QPushButton(self.horizontalLayoutWidget_3)\n        size_policy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Policy.Preferred,\n                                            QtWidgets.QSizePolicy.Policy.Preferred)\n        size_policy.setHorizontalStretch(0)\n        size_policy.setVerticalStretch(0)\n        size_policy.setHeightForWidth(self.menu_btn.sizePolicy().hasHeightForWidth())\n        self.menu_btn.setSizePolicy(size_policy)\n        self.menu_btn.setObjectName(\"menu_btn\")\n        self.menu_layout.addWidget(self.menu_btn)\n        self.reset_btn = QtWidgets.QPushButton(self.horizontalLayoutWidget_3)\n        size_policy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Policy.Preferred,\n                                            QtWidgets.QSizePolicy.Policy.Preferred)\n        size_policy.setHorizontalStretch(0)\n        size_policy.setVerticalStretch(0)\n        size_policy.setHeightForWidth(self.reset_btn.sizePolicy().hasHeightForWidth())\n        self.reset_btn.setSizePolicy(size_policy)\n        self.reset_btn.setObjectName(\"reset_btn\")\n        self.menu_layout.addWidget(self.reset_btn)\n\n        # assign VISCA PTZ to Serial Camera Source\n        self.assign_visca_ptz_btn = QtWidgets.QPushButton(self.manualControlPage)\n        self.assign_visca_ptz_btn.setGeometry(QtCore.QRect(10, 380, 141, 32))\n        self.assign_visca_ptz_btn.setObjectName(\"assign_visca_ptz_btn\")\n        self.assign_visca_ptz_btn.hide()\n        self.unassign_visca_ptz_btn = QtWidgets.QPushButton(self.manualControlPage)\n        self.unassign_visca_ptz_btn.setGeometry(QtCore.QRect(10, 380, 141, 32))\n        self.unassign_visca_ptz_btn.setObjectName(\"unassign_visca_ptz_btn\")\n        self.unassign_visca_ptz_btn.hide()\n        self.assign_visca_ptz_btn.clicked.connect(self.assign_visca_ptz_dlg)\n        self.unassign_visca_ptz_btn.clicked.connect(self.unassign_visca_ptz)\n        self.formTabWidget.addTab(self.manualControlPage, \"\")\n\n        self.gridLayout.addWidget(self.formTabWidget, 0, 0, 3, 1)\n\n        # enabled cameras view\n        self.flowLayout = FlowLayout()\n        self.gridLayout.addLayout(self.flowLayout, 0, 1, 1, 1)\n\n        # handling camera window sizing\n        self.screen_width = self.screen().availableGeometry().width()\n        self.screen_height = self.screen().availableGeometry().height()\n\n        # Create Dialog Object\n        self.dialogs = ShowDialog()\n\n        # Top Menu\n        self.menubar = QtWidgets.QMenuBar(self)\n        self.menubar.setGeometry(QtCore.QRect(0, 0, 705, 24))\n        self.menubar.setObjectName(\"menubar\")\n        self.menuFile = QtWidgets.QMenu(self.menubar)\n        self.menuFile.setObjectName(\"menuFile\")\n        self.menuSource = QtWidgets.QMenu(self.menubar)\n        self.menuSource.setObjectName(\"menuSource\")\n        self.menuFacial_Recognition = QtWidgets.QMenu(self.menubar)\n        self.menuFacial_Recognition.setObjectName(\"menuFacial_Recognition\")\n        self.menuHelp = QtWidgets.QMenu(self.menubar)\n        self.menuHelp.setObjectName(\"menuHelp\")\n        self.setMenuBar(self.menubar)\n        self.statusbar = QtWidgets.QStatusBar(self)\n        self.statusbar.setObjectName(\"statusbar\")\n        self.setStatusBar(self.statusbar)\n        self.actionOpen = QtWidgets.QWidgetAction(self)\n        self.actionOpen.setObjectName(\"actionOpen\")\n        self.actionSave = QtWidgets.QWidgetAction(self)\n        self.actionSave.setObjectName(\"actionSave\")\n        self.actionSave_as = QtWidgets.QWidgetAction(self)\n        self.actionSave_as.setObjectName(\"actionSave_as\")\n        self.actionClose = QtWidgets.QWidgetAction(self)\n        self.actionClose.setObjectName(\"actionClose\")\n        self.actionAdd_IP = QtWidgets.QWidgetAction(self)\n        self.actionAdd_IP.setObjectName(\"actionAdd_IP\")\n        self.menuAdd_NDI = QtWidgets.QMenu(self)\n        self.menuAdd_NDI.setObjectName(\"menuAdd_NDI\")\n        self.menuAdd_Hardware = QtWidgets.QMenu(self)\n        self.menuAdd_Hardware.setObjectName(\"menuAdd_Hardware\")\n        self.actionEdit = QtWidgets.QWidgetAction(self)\n        self.actionEdit.setObjectName(\"actionEdit\")\n        self.actionContact = QtWidgets.QWidgetAction(self)\n        self.actionContact.setObjectName(\"actionContact\")\n        self.actionAbout = QtWidgets.QWidgetAction(self)\n        self.actionAbout.setObjectName(\"actionAbout\")\n        self.actionAdd_Face = QtWidgets.QWidgetAction(self)\n        self.actionAdd_Face.setObjectName(\"actionAdd_Face\")\n        self.actionAdd_Face.triggered.connect(partial(self.dialogs.add_face, self.update_face_dropdown))\n        self.actionTrain_Model = QtWidgets.QWidgetAction(self)\n        self.actionTrain_Model.setObjectName(\"actionTrain_Model\")\n        self.actionTrain_Model.triggered.connect(partial(self.dialogs.retrain_face))\n        self.actionRemove_Face = QtWidgets.QWidgetAction(self)\n        self.actionRemove_Face.setObjectName(\"actionRemove_Face\")\n        self.actionRemove_Face.triggered.connect(partial(self.dialogs.remove_face, self.update_face_dropdown))\n        self.actionReset_Database = QtWidgets.QWidgetAction(self)\n        self.actionReset_Database.setObjectName(\"actionReset_Database\")\n        self.actionReset_Database.triggered.connect(partial(self.dialogs.reset_database, self.update_face_dropdown))\n        self.menuFile.addAction(self.actionOpen)\n        self.menuFile.addSeparator()\n        self.menuFile.addAction(self.actionSave)\n        self.menuFile.addAction(self.actionSave_as)\n        self.menuFile.addSeparator()\n        self.menuFile.addAction(self.actionClose)\n        self.menuSource.addAction(self.actionAdd_IP)\n        self.menuSource.addMenu(self.menuAdd_NDI)\n        self.menuSource.addMenu(self.menuAdd_Hardware)\n        self.menuSource.addSeparator()\n        self.menuSource.addAction(self.actionEdit)\n        self.menuFacial_Recognition.addAction(self.actionAdd_Face)\n        self.menuFacial_Recognition.addAction(self.actionTrain_Model)\n        self.menuFacial_Recognition.addAction(self.actionRemove_Face)\n        self.menuFacial_Recognition.addSeparator()\n        self.menuFacial_Recognition.addAction(self.actionReset_Database)\n        self.menuHelp.addAction(self.actionAbout)\n        self.menuHelp.addSeparator()\n        self.menuHelp.addAction(self.actionContact)\n        self.menubar.addAction(self.menuFile.menuAction())\n        self.menubar.addAction(self.menuSource.menuAction())\n        self.menubar.addAction(self.menuFacial_Recognition.menuAction())\n        self.menubar.addAction(self.menuHelp.menuAction())\n\n        self.current_selected_source = None\n        # other setup variables and methods\n        self.findNDISources()\n        self.findHardwareSources()\n\n        self.assigned_ptz_camera = []\n        self.serial_widget_list = []\n        if os.path.exists(constants.TRAINER_PATH) is False:\n            os.mkdir(constants.TRAINER_PATH)\n        self.watch_trainer = WatchTrainer()\n        observer = watchdog.observers.Observer()\n        observer.schedule(self.watch_trainer, path=constants.TRAINER_PATH, recursive=True)\n        observer.start()\n        self.translateUi(self)\n        QtCore.QMetaObject.connectSlotsByName(self)\n\n    def findHardwareSources(self):\n        \"\"\"Adds camera sources to the Hardware source list\"\"\"\n        available_cameras = QMediaDevices.videoInputs()\n\n        for index, cam in enumerate(available_cameras, start=0):\n            menu_item = QtWidgets.QWidgetAction(self)\n            menu_item.setText(cam.description())\n            menu_item.setCheckable(True)\n            menu_item.triggered.connect(\n                lambda source=index, item=menu_item: self.addCameraWidget(source=source, menu_item=item))\n            self.menuAdd_Hardware.addAction(menu_item)\n\n    def findNDISources(self):\n        \"\"\"Adds NDI sources to the NDI source list\"\"\"\n        source_list = get_ndi_sources()\n        for i, s in enumerate(source_list):\n            menu_item = QtWidgets.QWidgetAction(self)\n            menu_item.setText(s.ndi_name)\n            menu_item.setCheckable(True)\n            menu_item.triggered.connect(\n                lambda source=s, item=menu_item: self.addCameraWidget(source=s, menu_item=item, isNDI=True))\n            self.menuAdd_NDI.addAction(menu_item)\n\n    def addCameraWidget(self, source, menu_item, isNDI=False):\n        \"\"\"Add NDI/Serial camera source from the menu to the FlowLayout\"\"\"\n        camera_widget = CameraWidget(source=source, width=self.screen_width // 3, height=self.screen_height // 3, isNDI=isNDI)\n        camera_widget.change_selection_signal.connect(self.updateElements)\n        menu_item.triggered.disconnect()\n        menu_item.triggered.connect(\n            lambda index=source, item=menu_item: self.deleteCameraWidget(source=index, menu_item=item, camera_widget=camera_widget))\n        self.watch_trainer.add_camera(camera_widget=camera_widget)\n        self.flowLayout.addWidget(camera_widget)\n\n    def deleteCameraWidget(self, source, menu_item, camera_widget):\n        \"\"\"Remove NDI/Serial camera source from camera FlowLayout\"\"\"\n        menu_item.triggered.disconnect()\n        menu_item.triggered.connect(\n            lambda index=source, item=menu_item: self.addCameraWidget(source=index, menu_item=item))\n        self.watch_trainer.remove_camera(camera_widget=camera_widget)\n        if constants.CURRENT_ACTIVE_CAM_WIDGET == camera_widget:\n            constants.CURRENT_ACTIVE_CAM_WIDGET = None\n        camera_widget.stop()\n        camera_widget.deleteLater()\n\n    def updateElements(self):\n        \"\"\"\n        Update UI elements like FaceDropDownMenu and Enable Track Checkbox when a CameraWidget is activated/deactivated\n        \"\"\"\n        if constants.CURRENT_ACTIVE_CAM_WIDGET is None:\n            print(f\"No Camera Source is active\")\n            self.select_face_dropdown.setEnabled(False)\n            self.select_face_dropdown.setCurrentText('')\n            self.enable_track.setEnabled(False)\n            self.enable_track.setChecked(False)\n        else:\n            print(f\"{constants.CURRENT_ACTIVE_CAM_WIDGET.objectName()} is active\")\n            self.select_face_dropdown.setEnabled(True)\n            if constants.CURRENT_ACTIVE_CAM_WIDGET.processor_thread.is_alive():\n                print(\"Processor Thread is running\")\n                if constants.CURRENT_ACTIVE_CAM_WIDGET.get_tracked_name() is None:\n                    print(\"no tracked name\")\n                    self.select_face_dropdown.setCurrentText('')\n                    self.enable_track.setEnabled(False)\n                    self.enable_track.setChecked(False)\n                else:\n                    self.select_face_dropdown.setCurrentText(constants.CURRENT_ACTIVE_CAM_WIDGET.get_tracked_name())\n                    self.enable_track.setEnabled(True)\n                    if constants.CURRENT_ACTIVE_CAM_WIDGET.get_tracking() is False:\n                        self.enable_track.setChecked(False)\n                        print(\"a tracked name but not tracking\")\n                    else:\n                        self.enable_track.setChecked(True)\n                        print(\"a tracked name and tracking\")\n            else:\n                print(\"Processor Thread is not running\")\n                self.select_face_dropdown.setEnabled(True)\n                self.select_face_dropdown.setCurrentText('')\n                self.enable_track.setEnabled(False)\n                self.enable_track.setChecked(False)\n\n    def selected_face_change(self):\n        if constants.CURRENT_ACTIVE_CAM_WIDGET is not None:\n            if self.select_face_dropdown.currentText() == '':\n                constants.CURRENT_ACTIVE_CAM_WIDGET.set_tracked_name(None)\n                self.enable_track.setEnabled(False)\n                self.enable_track.setChecked(False)\n            else:\n                constants.CURRENT_ACTIVE_CAM_WIDGET.set_tracked_name(self.select_face_dropdown.currentText())\n                self.enable_track.setEnabled(True)\n\n    def enable_track_change(self):\n        if constants.CURRENT_ACTIVE_CAM_WIDGET is not None:\n            if constants.CURRENT_ACTIVE_CAM_WIDGET.processor_thread.is_alive() and constants.CURRENT_ACTIVE_CAM_WIDGET.get_tracking() and self.enable_track.isChecked():\n                pass\n            else:\n                constants.CURRENT_ACTIVE_CAM_WIDGET.set_tracking()\n                self.enable_track.setChecked(constants.CURRENT_ACTIVE_CAM_WIDGET.get_tracking())\n        else:\n            self.enable_track.setChecked(False)\n\n    def init_manual_control(self, device):\n        \"\"\"Initializing manual camera control. ONLY VISCA devices for now.\"\"\"\n        self.current_manual_device = ViscaPTZ(device_id=device)\n\n        if device != \"\":\n            # Enable Button Commands\n            self.up_left_btn.clicked.connect(self.current_manual_device.move_left_up)\n            self.up_btn.clicked.connect(self.current_manual_device.move_up)\n            self.up_right_btn.clicked.connect(self.current_manual_device.move_right_up)\n            self.left_btn.clicked.connect(self.current_manual_device.move_left)\n            self.right_btn.clicked.connect(self.current_manual_device.move_right)\n            self.down_left_btn.clicked.connect(self.current_manual_device.move_left_down)\n            self.down_btn.clicked.connect(self.current_manual_device.move_down)\n            self.down_right_btn.clicked.connect(self.current_manual_device.move_right_down)\n            self.home_btn.clicked.connect(self.current_manual_device.move_home)\n            self.zoom_in_btn.clicked.connect(self.current_manual_device.zoom_in)\n            self.zoom_out_btn.clicked.connect(self.current_manual_device.zoom_out)\n            self.menu_btn.clicked.connect(self.current_manual_device.menu)\n            self.reset_btn.clicked.connect(self.current_manual_device.reset)\n        else:\n            # Disable Button Commands\n            self.up_left_btn.clicked.disconnect()\n            self.up_btn.clicked.disconnect()\n            self.up_right_btn.clicked.disconnect()\n            self.left_btn.clicked.disconnect()\n            self.right_btn.clicked.disconnect()\n            self.down_left_btn.clicked.disconnect()\n            self.down_btn.clicked.disconnect()\n            self.down_right_btn.clicked.disconnect()\n            self.home_btn.clicked.disconnect()\n            self.zoom_in_btn.clicked.disconnect()\n            self.zoom_out_btn.clicked.disconnect()\n            self.menu_btn.clicked.disconnect()\n            self.reset_btn.clicked.disconnect()\n\n        # shows button depending on if device has already been assigned to a camera source\n        try:\n            if device in self.assigned_ptz_camera:\n                self.unassign_visca_ptz_btn.show()\n            else:\n                self.assign_visca_ptz_btn.show()\n        except Exception as e:\n            print(e)\n            self.assign_visca_ptz_btn.hide()\n            self.unassign_visca_ptz_btn.hide()\n\n    def assign_visca_ptz_dlg(self):\n        \"\"\"Launch the Assign VISCA PTZ to Camera Source dialog.\"\"\"\n        if not self.serial_widget_list or self.select_camera_dropdown.currentText() == \"\":\n            print(\"Need to select or add a camera\")\n        else:\n            dlg = AssignViscaPTZDlg(self, camera_list=self.serial_widget_list, assigned_list=self.assigned_ptz_camera,\n                                    ptz_id=self.select_camera_dropdown.currentText())\n            dlg.closeEvent = self.refreshViscaBtn\n            dlg.exec()\n\n    def unassign_visca_ptz(self):\n        \"\"\"Allow User to Unassign current VISCA PTZ device from Camera Source\"\"\"\n        index = self.assigned_ptz_camera.index(self.select_camera_dropdown.currentText())\n\n        camera = self.assigned_ptz_camera[index + 1]\n        camera.image_processor.set_ptz_controller(None)\n        self.assigned_ptz_camera.remove(camera)\n        self.assigned_ptz_camera.remove(self.select_camera_dropdown.currentText())\n\n        self.unassign_visca_ptz_btn.hide()\n        self.assign_visca_ptz_btn.show()\n\n    def assign_network_ptz_dlg(self):\n        \"\"\"Launch the Assign Network PTZ to Camera Source dialog.\"\"\"\n        if not self.current_selected_source:\n            print(\"Need to select or add a camera\")\n        else:\n            dlg = AssignNetworkPTZDlg(self, camera=self.current_selected_source)\n            dlg.closeEvent = self.refreshNetworkBtn\n            dlg.exec()\n\n    def unassign_network_ptz(self):\n        \"\"\"Allow User to Unassign current Network PTZ device from Camera Source\"\"\"\n        self.current_selected_source.image_processor.set_ptz_controller(control=None)\n        self.current_selected_source.image_processor.set_ptz_ready(\"not ready\")\n        self.unassign_network_ptz_btn.hide()\n        self.assign_network_ptz_btn.show()\n\n    def update_face_dropdown(self, event):\n        current_text_temp = self.select_face_dropdown.currentText()\n        self.select_face_dropdown.clear()\n        self.select_face_dropdown.addItem('')\n        if os.path.exists(constants.IMAGE_PATH):\n            for folder in os.listdir(constants.IMAGE_PATH):\n                self.select_face_dropdown.addItem(folder)\n            if self.select_face_dropdown.findText(current_text_temp) != -1:\n                self.select_face_dropdown.setCurrentText(current_text_temp)\n\n    def refreshViscaBtn(self, event):\n        \"\"\"Check is VISCA PTZ is assigned and change assignment button if so\"\"\"\n        if self.select_camera_dropdown.currentText() in self.assigned_ptz_camera:\n            self.unassign_visca_ptz_btn.show()\n            self.assign_visca_ptz_btn.hide()\n        else:\n            self.assign_visca_ptz_btn.show()\n            self.unassign_visca_ptz_btn.hide()\n\n    def refreshNetworkBtn(self, event):\n        \"\"\"Check is Network PTZ is assigned and change assignment button if so\"\"\"\n        if self.current_selected_source.image_processor.get_ptz_ready() == \"ready\":\n            self.unassign_network_ptz_btn.show()\n            self.assign_network_ptz_btn.hide()\n        else:\n            self.assign_network_ptz_btn.show()\n            self.unassign_network_ptz_btn.hide()\n\n    def translateUi(self, AutoPTZ):\n        \"\"\"Translate Menu, Buttons, and Labels through localization\"\"\"\n        _translate = QtCore.QCoreApplication.translate\n        AutoPTZ.setWindowTitle(_translate(\"AutoPTZ\", \"AutoPTZ\"))\n        self.enable_track.setText(_translate(\"AutoPTZ\", \"Enable Tracking\"))\n        self.select_face_label.setText(_translate(\"AutoPTZ\", \"Select Face\"))\n        self.assign_network_ptz_btn.setText(_translate(\"AutoPTZ\", \"Assign Network PTZ\"))\n        self.unassign_network_ptz_btn.setText(_translate(\"AutoPTZ\", \"Unassign Network PTZ\"))\n        self.formTabWidget.setTabText(self.formTabWidget.indexOf(self.selectedCamPage), _translate(\"AutoPTZ\", \"Auto\"))\n        self.select_camera_label.setText(_translate(\"AutoPTZ\", \"Select Camera\"))\n        self.down_right_btn.setText(_translate(\"AutoPTZ\", \"↘\"))\n        self.up_btn.setText(_translate(\"AutoPTZ\", \"↑\"))\n        self.up_left_btn.setText(_translate(\"AutoPTZ\", \"↖\"))\n        self.left_btn.setText(_translate(\"AutoPTZ\", \"←\"))\n        self.down_left_btn.setText(_translate(\"AutoPTZ\", \"↙\"))\n        self.up_right_btn.setText(_translate(\"AutoPTZ\", \"↗\"))\n        self.right_btn.setText(_translate(\"AutoPTZ\", \"→\"))\n        self.down_btn.setText(_translate(\"AutoPTZ\", \"↓\"))\n        self.home_btn.setText(_translate(\"AutoPTZ\", \"⌂\"))\n        self.zoom_in_btn.setText(_translate(\"AutoPTZ\", \"Zoom +\"))\n        self.zoom_out_btn.setText(_translate(\"AutoPTZ\", \"Zoom -\"))\n        self.focus_plus_btn.setText(_translate(\"AutoPTZ\", \"Focus +\"))\n        self.focus_minus_btn.setText(_translate(\"AutoPTZ\", \"Focus -\"))\n        self.menu_btn.setText(_translate(\"AutoPTZ\", \"Menu\"))\n        self.reset_btn.setText(_translate(\"AutoPTZ\", \"Reset\"))\n        self.assign_visca_ptz_btn.setText(_translate(\"AutoPTZ\", \"Assign VISCA PTZ\"))\n        self.unassign_visca_ptz_btn.setText(_translate(\"AutoPTZ\", \"Unassign VISCA PTZ\"))\n        self.formTabWidget.setTabText(self.formTabWidget.indexOf(self.manualControlPage),\n                                      _translate(\"AutoPTZ\", \"Manual\"))\n        self.menuFile.setTitle(_translate(\"AutoPTZ\", \"File\"))\n        self.menuSource.setTitle(_translate(\"AutoPTZ\", \"Sources\"))\n        self.menuFacial_Recognition.setTitle(_translate(\"AutoPTZ\", \"Facial Recognition\"))\n        self.menuHelp.setTitle(_translate(\"AutoPTZ\", \"Help\"))\n        self.actionOpen.setText(_translate(\"AutoPTZ\", \"Open\"))\n        self.actionSave.setText(_translate(\"AutoPTZ\", \"Save\"))\n        self.actionSave_as.setText(_translate(\"AutoPTZ\", \"Save As\"))\n        self.actionClose.setText(_translate(\"AutoPTZ\", \"Close\"))\n        self.actionAdd_IP.setText(_translate(\"AutoPTZ\", \"Add IP\"))\n        self.menuAdd_NDI.setTitle(_translate(\"AutoPTZ\", \"Add NDI\"))\n        self.menuAdd_Hardware.setTitle(_translate(\"AutoPTZ\", \"Add Hardware\"))\n        self.actionEdit.setText(_translate(\"AutoPTZ\", \"Edit Setup\"))\n        self.actionContact.setText(_translate(\"AutoPTZ\", \"Contact\"))\n        self.actionAbout.setText(_translate(\"AutoPTZ\", \"About\"))\n        self.actionAdd_Face.setText(_translate(\"AutoPTZ\", \"Add Face\"))\n        self.actionTrain_Model.setText(_translate(\"AutoPTZ\", \"Retrain Model\"))\n        self.actionRemove_Face.setText(_translate(\"AutoPTZ\", \"Remove Face\"))\n        self.actionReset_Database.setText(_translate(\"AutoPTZ\", \"Reset Database\"))\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/views/homepage/main_window.py b/views/homepage/main_window.py
--- a/views/homepage/main_window.py	(revision ddfcc307b70213f1b1cd12fe34f293537998ffeb)
+++ b/views/homepage/main_window.py	(date 1669102925985)
@@ -474,7 +474,7 @@
         else:
             print(f"{constants.CURRENT_ACTIVE_CAM_WIDGET.objectName()} is active")
             self.select_face_dropdown.setEnabled(True)
-            if constants.CURRENT_ACTIVE_CAM_WIDGET.processor_thread.is_alive():
+            if constants.CURRENT_ACTIVE_CAM_WIDGET.processor_thread.isRunning():
                 print("Processor Thread is running")
                 if constants.CURRENT_ACTIVE_CAM_WIDGET.get_tracked_name() is None:
                     print("no tracked name")
@@ -509,7 +509,7 @@
 
     def enable_track_change(self):
         if constants.CURRENT_ACTIVE_CAM_WIDGET is not None:
-            if constants.CURRENT_ACTIVE_CAM_WIDGET.processor_thread.is_alive() and constants.CURRENT_ACTIVE_CAM_WIDGET.get_tracking() and self.enable_track.isChecked():
+            if constants.CURRENT_ACTIVE_CAM_WIDGET.processor_thread.isRunning() and constants.CURRENT_ACTIVE_CAM_WIDGET.get_tracking() and self.enable_track.isChecked():
                 pass
             else:
                 constants.CURRENT_ACTIVE_CAM_WIDGET.set_tracking()
Index: logic/facial_tracking/testing_person_tracking.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/logic/facial_tracking/testing_person_tracking.py b/logic/facial_tracking/testing_person_tracking.py
new file mode 100644
--- /dev/null	(date 1669144292757)
+++ b/logic/facial_tracking/testing_person_tracking.py	(date 1669144292757)
@@ -0,0 +1,67 @@
+import dlib
+import cv2
+from PySide6.QtCore import QThread
+
+
+class Tracker(QThread):
+
+    def __init__(self, stream_thread):
+        super().__init__()
+        self._run_flag = True
+        self.stream = stream_thread
+        self.tracker = None
+        self.temp_tracked_name = None
+        self.is_tracking = False  # If Track Checkbox is checked
+        self.tracked_name = None  # Face that needs to be tracked
+
+        self.track_x = None
+        self.track_y = None
+        self.track_w = None
+        self.track_h = None
+
+    def run(self):
+        while self._run_flag:
+            frame = self.stream.cv_img
+            self.track_face(frame)
+        else:
+            self.stop()
+
+    def stop(self):
+        """Sets run flag to False and waits for thread to finish"""
+        self._run_flag = False
+        self.wait()
+        self.deleteLater()
+
+    def track_face(self, frame):
+        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
+        if self.tracker is None and self.track_x is not None:
+            self.tracker = dlib.correlation_tracker()
+            rect = dlib.rectangle(self.track_x, self.track_y, self.track_w, self.track_h)
+            self.tracker.start_track(rgb_frame, rect)
+            self.track_x = None
+            self.track_y = None
+            self.track_w = None
+            self.track_h = None
+        if self.tracker is not None and self.temp_tracked_name == self.tracked_name and self.track_x is not None:
+            rect = dlib.rectangle(self.track_x, self.track_y, self.track_w, self.track_h)
+            self.tracker.start_track(rgb_frame, rect)
+            self.track_x = None
+            self.track_y = None
+            self.track_w = None
+            self.track_h = None
+        elif self.tracker is not None:
+            self.tracker.update(rgb_frame)
+            pos = self.tracker.get_position()
+            # unpack the position object
+            self.track_x = int(pos.left())
+            self.track_y = int(pos.top())
+            self.track_w = int(pos.right())
+            self.track_h = int(pos.bottom())
+        self.temp_tracked_name = None
+
+    def set_tracking_positions(self, x, y, w, h, name):
+        self.track_x = x
+        self.track_y = y
+        self.track_w = w
+        self.track_h = h
+        self.temp_tracked_name = name
Index: views/widgets/camera_widget.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from PySide6 import QtGui\nfrom PySide6.QtWidgets import QLabel\nfrom PySide6.QtGui import QPixmap\nfrom PySide6.QtCore import Qt\nfrom PySide6.QtCore import Signal\nimport cv2\nimport time\nimport imutils\nimport dlib\nimport shared.constants as constants\nfrom logic.facial_tracking.testing_image_processor import ImageProcessor\nfrom views.widgets.video_thread import VideoThread\n\n\nclass CameraWidget(QLabel):\n    \"\"\"\n    Create and handle all Cameras that are added to the UI.\n    It creates a QLabel as OpenCV and NDI video can be converted to QPixmap for display.\n    Combines both VideoThread and ImageProcessor threads for asynchronous computation for smoother looking video.\n    \"\"\"\n    change_selection_signal = Signal()\n    # FPS for Performance\n    start_time = time.time()\n    display_time = 2\n    fc = 0\n    FPS = 0\n\n    def __init__(self, source, width, height, isNDI=False):\n        super().__init__()\n        self.width = width\n        self.height = height\n        self.setProperty('active', False)\n        # self.resize(width, height)\n        self.setObjectName(f\"Camera Source: {source}\")\n        self.setStyleSheet(constants.CAMERA_STYLESHEET)\n        self.setText(f\"Camera Source: {source}\")\n        self.mouseReleaseEvent = lambda event, widget=self: self.clicked_widget(event, widget)\n\n        # Create Video Capture Thread\n        self.stream_thread = VideoThread(src=source, width=width, isNDI=isNDI)\n        # Connect it's Signal to the update_image Slot Method\n        self.stream_thread.change_pixmap_signal.connect(self.update_image)\n        # Start the Thread\n        self.stream_thread.start()\n\n        # Create and Run Image Processor Thread\n        self.processor_thread = ImageProcessor(stream_thread=self.stream_thread)\n        self.processor_thread.start()\n\n        self.tracker = None\n        self.temp_tracked_name = None\n        self.track_x = None\n        self.track_y = None\n        self.track_w = None\n        self.track_h = None\n        self.is_tracking = False  # If Track Checkbox is checked\n        self.tracked_name = None  # Face that needs to be tracked\n\n    def stop(self):\n        \"\"\"\n        When CameraWidget is being removed from the UI, we should stop all relevant threads before deletion.\n        \"\"\"\n        self.processor_thread.stop()\n        self.stream_thread.stop()\n        self.deleteLater()\n\n    def set_add_name(self, name):\n        \"\"\"\n        Run when the user wants to register a new face for recognition.\n        If the Processor thread is already alive then just set the name to start taking images,\n        If the Processor thread is not alive then start up the thread, then add the face.\n        :param name:\n        \"\"\"\n        if self.processor_thread.is_alive():\n            self.processor_thread.add_name = name\n        else:\n            print(f\"starting ImageProcessor Thread for {self.objectName()}\")\n            # Create and Run Image Processor Thread\n            self.processor_thread = ImageProcessor(stream_thread=self.stream_thread)\n            self.processor_thread.add_name = name\n            self.processor_thread.start()\n\n    def check_encodings(self):\n        \"\"\"\n        Run when the user resets database or train a model.\n        If the Processor thread is already alive then tell the thread to check encodings again.\n        If the Processor thread is not alive then start up the thread, the thread will automatically check encodings.\n        \"\"\"\n        if self.processor_thread.is_alive():\n            self.processor_thread.check_encodings()\n        else:\n            print(f\"starting ImageProcessor Thread for {self.objectName()}\")\n            self.processor_thread = ImageProcessor(stream_thread=self.stream_thread)\n            self.processor_thread.start()\n\n    def set_tracking(self):\n        self.is_tracking = not self.is_tracking\n\n    def set_tracked_name(self, name):\n        self.tracked_name = name\n\n    def get_tracked_name(self):\n        return self.tracked_name\n\n    def get_tracking(self):\n        return self.is_tracking\n\n    def update_image(self, cv_img):\n        \"\"\"Updates the QLabel with the latest OpenCV/NDI frame and draws it\"\"\"\n        cv_img = self.draw_on_frame(frame=cv_img, face_locations=self.processor_thread.face_locations,\n                                    face_names=self.processor_thread.face_names,\n                                    confidence_list=self.processor_thread.confidence_list)\n        qt_img = self.convert_cv_qt(cv_img)\n        self.setPixmap(qt_img)\n\n    def convert_cv_qt(self, cv_img):\n        \"\"\"Convert from an opencv image to QPixmap\"\"\"\n        rgb_image = cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB)\n        h, w, ch = rgb_image.shape\n        bytes_per_line = ch * w\n        convert_to_qt_format = QtGui.QImage(rgb_image.data, w, h, bytes_per_line, QtGui.QImage.Format.Format_RGB888)\n        p = convert_to_qt_format.scaled(self.width, self.height, Qt.AspectRatioMode.KeepAspectRatio)\n        return QPixmap.fromImage(p)\n\n    def clicked_widget(self, event, widget):\n        \"\"\"\n        First checks if there is another CameraWidget currently active. If it is then deactivate it and update their stylesheet.\n        Then if that deactivated CameraWidget is the same CameraWidget currently clicked on, then remove it from constants. So nothing is active.\n        If it is not the same CameraWidget, then update this clicked on CameraWidget to be active and update its stylesheet.\n        :param event:\n        :param widget:\n        \"\"\"\n        if constants.CURRENT_ACTIVE_CAM_WIDGET is not None:\n            constants.CURRENT_ACTIVE_CAM_WIDGET.setProperty(\n                'active', not constants.CURRENT_ACTIVE_CAM_WIDGET.property('active'))\n            constants.CURRENT_ACTIVE_CAM_WIDGET.style().unpolish(constants.CURRENT_ACTIVE_CAM_WIDGET)\n            constants.CURRENT_ACTIVE_CAM_WIDGET.style().polish(constants.CURRENT_ACTIVE_CAM_WIDGET)\n            constants.CURRENT_ACTIVE_CAM_WIDGET.update()\n\n        if constants.CURRENT_ACTIVE_CAM_WIDGET == widget:\n            constants.CURRENT_ACTIVE_CAM_WIDGET = None\n        else:\n            constants.CURRENT_ACTIVE_CAM_WIDGET = widget\n            constants.CURRENT_ACTIVE_CAM_WIDGET.setProperty(\n                'active', not constants.CURRENT_ACTIVE_CAM_WIDGET.property('active'))\n            constants.CURRENT_ACTIVE_CAM_WIDGET.style().unpolish(constants.CURRENT_ACTIVE_CAM_WIDGET)\n            constants.CURRENT_ACTIVE_CAM_WIDGET.style().polish(constants.CURRENT_ACTIVE_CAM_WIDGET)\n            constants.CURRENT_ACTIVE_CAM_WIDGET.update()\n        self.change_selection_signal.emit()\n\n    def draw_on_frame(self, frame, face_locations, face_names, confidence_list):\n        \"\"\"\n        Is called by update_image and returns the latest frame with FPS + face box drawings if there are any.\n        :param frame:\n        :param face_locations:\n        :param face_names:\n        :param confidence_list:\n        :return:\n        \"\"\"\n        if face_locations is not None and face_names is not None and confidence_list is not None:\n            for (top, right, bottom, left), name, confidence in zip(face_locations, face_names, confidence_list):\n                # Scale back up face locations since the frame we detected in was scaled to 1/2 size\n                top *= 2\n                right *= 2\n                bottom *= 2\n                left *= 2\n\n                if name == self.tracked_name:\n                    self.temp_tracked_name = name\n                    self.track_x = left\n                    self.track_y = top\n                    self.track_w = right\n                    self.track_h = bottom\n                # Draw a box around the face\n                cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n                # Draw a label with name and confidence for the face\n                cv2.putText(frame, name, (left + 5, top - 5), constants.FONT, 0.5, (255, 255, 255), 1)\n                cv2.putText(frame, confidence, (right - 52, bottom - 5), constants.FONT, 0.45, (255, 255, 0), 1)\n\n        if self.is_tracking and self.processor_thread.is_alive():\n            frame = self.track_face(frame)\n\n        # FPS Counter\n        self.fc += 1\n        time_set = time.time() - self.start_time\n        if time_set >= self.display_time:\n            self.FPS = self.fc / time_set\n            self.fc = 0\n            self.start_time = time.time()\n        fps = \"FPS: \" + str(self.FPS)[:5]\n\n        cv2.putText(frame, fps, (50, 50), constants.FONT, 1, (0, 0, 255), 2)\n        return frame\n\n    def track_face(self, frame):  # Probably needs to be on its own thread\n        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n        if self.tracker is None and self.track_x is not None:\n            self.tracker = dlib.correlation_tracker()\n            rect = dlib.rectangle(self.track_x, self.track_y, self.track_w, self.track_h)\n            self.tracker.start_track(rgb_frame, rect)\n            cv2.putText(frame, \"tracking\", (self.track_x, self.track_h + 15), constants.FONT, 0.45, (0, 255, 0), 1)\n            cv2.rectangle(frame, (self.track_x, self.track_y), (self.track_w, self.track_h), (255, 0, 255), 3, 1)\n        if self.tracker is not None and self.temp_tracked_name == self.tracked_name and self.track_x is not None:\n            rect = dlib.rectangle(self.track_x, self.track_y, self.track_w, self.track_h)\n            self.tracker.start_track(rgb_frame, rect)\n            cv2.putText(frame, \"tracking\", (self.track_x, self.track_h + 15), constants.FONT, 0.45, (0, 255, 0), 1)\n            cv2.rectangle(frame, (self.track_x, self.track_y), (self.track_w, self.track_h), (255, 0, 255), 3, 1)\n        elif self.tracker is not None:\n            self.tracker.update(rgb_frame)\n            pos = self.tracker.get_position()\n            # unpack the position object\n            self.track_x = int(pos.left())\n            self.track_y = int(pos.top())\n            self.track_w = int(pos.right())\n            self.track_h = int(pos.bottom())\n            cv2.putText(frame, \"tracking\", (self.track_x, self.track_h + 15), constants.FONT, 0.45, (0, 255, 0), 1)\n            cv2.rectangle(frame, (self.track_x, self.track_y), (self.track_w, self.track_h), (255, 0, 255), 3, 1)\n\n        self.track_x = None\n        self.track_y = None\n        self.track_w = None\n        self.track_h = None\n        self.temp_tracked_name = None\n        return frame\n\n    def closeEvent(self, event):\n        \"\"\"\n        On event call, stop all the related threads.\n        :param event:\n        \"\"\"\n        self.processor_thread.stop()\n        self.stream_thread.stop()\n        event.accept()\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/views/widgets/camera_widget.py b/views/widgets/camera_widget.py
--- a/views/widgets/camera_widget.py	(revision ddfcc307b70213f1b1cd12fe34f293537998ffeb)
+++ b/views/widgets/camera_widget.py	(date 1669144374977)
@@ -9,6 +9,7 @@
 import dlib
 import shared.constants as constants
 from logic.facial_tracking.testing_image_processor import ImageProcessor
+from logic.facial_tracking.testing_person_tracking import Tracker
 from views.widgets.video_thread import VideoThread
 
 
@@ -47,19 +48,15 @@
         self.processor_thread = ImageProcessor(stream_thread=self.stream_thread)
         self.processor_thread.start()
 
-        self.tracker = None
-        self.temp_tracked_name = None
-        self.track_x = None
-        self.track_y = None
-        self.track_w = None
-        self.track_h = None
-        self.is_tracking = False  # If Track Checkbox is checked
-        self.tracked_name = None  # Face that needs to be tracked
+        # Create and Run Tracking Thread
+        self.tracker_thread = Tracker(stream_thread=self.stream_thread)
+        self.tracker_thread.start()
 
     def stop(self):
         """
         When CameraWidget is being removed from the UI, we should stop all relevant threads before deletion.
         """
+        self.tracker_thread.stop()
         self.processor_thread.stop()
         self.stream_thread.stop()
         self.deleteLater()
@@ -71,7 +68,7 @@
         If the Processor thread is not alive then start up the thread, then add the face.
         :param name:
         """
-        if self.processor_thread.is_alive():
+        if self.processor_thread.isRunning():
             self.processor_thread.add_name = name
         else:
             print(f"starting ImageProcessor Thread for {self.objectName()}")
@@ -86,7 +83,7 @@
         If the Processor thread is already alive then tell the thread to check encodings again.
         If the Processor thread is not alive then start up the thread, the thread will automatically check encodings.
         """
-        if self.processor_thread.is_alive():
+        if self.processor_thread.isRunning():
             self.processor_thread.check_encodings()
         else:
             print(f"starting ImageProcessor Thread for {self.objectName()}")
@@ -94,16 +91,16 @@
             self.processor_thread.start()
 
     def set_tracking(self):
-        self.is_tracking = not self.is_tracking
+        self.tracker_thread.is_tracking = not self.tracker_thread.is_tracking
 
     def set_tracked_name(self, name):
-        self.tracked_name = name
+        self.tracker_thread.tracked_name = name
 
     def get_tracked_name(self):
-        return self.tracked_name
+        return self.tracker_thread.tracked_name
 
     def get_tracking(self):
-        return self.is_tracking
+        return self.tracker_thread.is_tracking
 
     def update_image(self, cv_img):
         """Updates the QLabel with the latest OpenCV/NDI frame and draws it"""
@@ -165,20 +162,17 @@
                 bottom *= 2
                 left *= 2
 
-                if name == self.tracked_name:
-                    self.temp_tracked_name = name
-                    self.track_x = left
-                    self.track_y = top
-                    self.track_w = right
-                    self.track_h = bottom
+                if name == self.tracker_thread.tracked_name:
+                    self.tracker_thread.set_tracking_positions(x=left, y=top, w=right, h=bottom, name=name)
                 # Draw a box around the face
                 cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)
                 # Draw a label with name and confidence for the face
                 cv2.putText(frame, name, (left + 5, top - 5), constants.FONT, 0.5, (255, 255, 255), 1)
                 cv2.putText(frame, confidence, (right - 52, bottom - 5), constants.FONT, 0.45, (255, 255, 0), 1)
 
-        if self.is_tracking and self.processor_thread.is_alive():
-            frame = self.track_face(frame)
+        if self.tracker_thread.is_tracking and self.processor_thread.isRunning() and self.tracker_thread.track_x is not None:
+            cv2.putText(frame, "tracking", (self.tracker_thread.track_x, self.tracker_thread.track_h + 15), constants.FONT, 0.45, (0, 255, 0), 1)
+            cv2.rectangle(frame, (self.tracker_thread.track_x, self.tracker_thread.track_y), (self.tracker_thread.track_w, self.tracker_thread.track_h), (255, 0, 255), 3, 1)
 
         # FPS Counter
         self.fc += 1
@@ -192,42 +186,12 @@
         cv2.putText(frame, fps, (50, 50), constants.FONT, 1, (0, 0, 255), 2)
         return frame
 
-    def track_face(self, frame):  # Probably needs to be on its own thread
-        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
-        if self.tracker is None and self.track_x is not None:
-            self.tracker = dlib.correlation_tracker()
-            rect = dlib.rectangle(self.track_x, self.track_y, self.track_w, self.track_h)
-            self.tracker.start_track(rgb_frame, rect)
-            cv2.putText(frame, "tracking", (self.track_x, self.track_h + 15), constants.FONT, 0.45, (0, 255, 0), 1)
-            cv2.rectangle(frame, (self.track_x, self.track_y), (self.track_w, self.track_h), (255, 0, 255), 3, 1)
-        if self.tracker is not None and self.temp_tracked_name == self.tracked_name and self.track_x is not None:
-            rect = dlib.rectangle(self.track_x, self.track_y, self.track_w, self.track_h)
-            self.tracker.start_track(rgb_frame, rect)
-            cv2.putText(frame, "tracking", (self.track_x, self.track_h + 15), constants.FONT, 0.45, (0, 255, 0), 1)
-            cv2.rectangle(frame, (self.track_x, self.track_y), (self.track_w, self.track_h), (255, 0, 255), 3, 1)
-        elif self.tracker is not None:
-            self.tracker.update(rgb_frame)
-            pos = self.tracker.get_position()
-            # unpack the position object
-            self.track_x = int(pos.left())
-            self.track_y = int(pos.top())
-            self.track_w = int(pos.right())
-            self.track_h = int(pos.bottom())
-            cv2.putText(frame, "tracking", (self.track_x, self.track_h + 15), constants.FONT, 0.45, (0, 255, 0), 1)
-            cv2.rectangle(frame, (self.track_x, self.track_y), (self.track_w, self.track_h), (255, 0, 255), 3, 1)
-
-        self.track_x = None
-        self.track_y = None
-        self.track_w = None
-        self.track_h = None
-        self.temp_tracked_name = None
-        return frame
-
     def closeEvent(self, event):
         """
         On event call, stop all the related threads.
         :param event:
         """
+        self.tracker_thread.stop()
         self.processor_thread.stop()
         self.stream_thread.stop()
         event.accept()
